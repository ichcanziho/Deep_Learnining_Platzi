# Curso de Desarrollo de Chatbots con OpenAI

Aprende a usar la API de OpenAI para desarrollar un chatbot con identidad propia. Da este paso hacia una experiencia conversacional impulsada por la inteligencia artificial con GPT-4, GPT-3.5 y Davinci.

- Integra un LLM de OpenAI a una aplicaci칩n de chat.
- Estima el costo de consumo por tokens de la API.
- Aplica fine-tuning a un modelo para personalizarlo.


> ## NOTA:
> Antes de continuar te invito a que revises los cursos anteriores:
> - [1: Curso profesional de Redes Neuronales con TensorFlow](https://github.com/ichcanziho/Deep_Learnining_Platzi/tree/master/1%20Curso%20de%20fundamentos%20de%20redes%20neuronales)
> - [2: Curso de Redes Neuronales Convolucionales con Python y keras](https://github.com/ichcanziho/Deep_Learnining_Platzi/tree/master/2%20Curso%20de%20Redes%20Neuronales%20Convolucionales)
> - [3: Curso profesional de Redes Neuronales con TensorFlow](https://github.com/ichcanziho/Deep_Learnining_Platzi/tree/master/3%20Curso%20profesional%20de%20Redes%20Neuronales%20con%20TensorFlow)
> - [4: Curso de Transfer Learning con Hugging Face](https://github.com/ichcanziho/Deep_Learnining_Platzi/tree/master/4%20Curso%20de%20Transfer%20Learning%20con%20Hugging%20Face)
> - [5: Curso de Experimentaci칩n en Machine Learning con Hugging Face](https://github.com/ichcanziho/Deep_Learnining_Platzi/tree/master/5%20Curso%20de%20introducci%C3%B3n%20a%20Demos%20de%20Machine%20Learning%20con%20Hugging%20Face)
> - [6: Curso de detecci칩n y segmentaci칩n de objetos con TensorFlow](https://github.com/ichcanziho/Deep_Learnining_Platzi/tree/master/6%20Curso%20de%20detecci%C3%B3n%20y%20segmentaci%C3%B3n%20de%20objetos%20con%20Tensorflow)
> - [7: Curso profesional de Computer Vision con TensorFlow](https://github.com/ichcanziho/Deep_Learnining_Platzi/tree/master/7%20Curso%20profesional%20de%20Computer%20Vision%20con%20TensorFlow)
> - [8: Curso de generaci칩n de im치genes](https://github.com/ichcanziho/Deep_Learnining_Platzi/tree/master/8%20Curso%20de%20generaci%C3%B3n%20de%20im%C3%A1genes)
> - [9: Cursos de Fundamentos de NLP](https://github.com/ichcanziho/Deep_Learnining_Platzi/tree/master/9%20Curso%20de%20Fundamentos%20de%20NLP)
> - [10: Curso de Fundamentos de Procesamiento de Lenguaje Natural con Python y NLTK](https://github.com/ichcanziho/Deep_Learnining_Platzi/tree/master/10%20Curso%20de%20Algoritmos%20de%20Clasificaci%C3%B3n%20de%20Texto)
> - [11: Curso de redes Neuronales con PyTorch]
> - 
> Este Curso es el N칰mero 12 de una ruta de Deep Learning, quiz치 algunos conceptos no vuelvan a ser definidos en este repositorio,
> por eso es indispensable que antes de empezar a leer esta gu칤a hayas comprendido los temas vistos anteriormente.
> 
> Sin m치s por agregar disfruta de este curso


# 칈NDICE:

- [1 OpenAI API](#1-openai-api)
  - [1.1 쮺칩mo usar la API de OpenAI en tu producto?](#11-c칩mo-usar-la-api-de-openai-en-tu-producto)
  - [1.2 Conociendo la documentaci칩n de la API de OpenAI](#12-conociendo-la-documentaci칩n-de-la-api-de-openai)
  - [1.3 Cargar modelo de la API de OpenAI con Python](#13-cargar-modelo-de-la-api-de-openai-con-python)
  - [1.4 Creaci칩n de ejemplo utilizando la API de OpenAI](#14-creaci칩n-de-ejemplo-utilizando-la-api-de-openai)
  - [1.5 Par치metros de Text Completion: temperature, top_p y n](#15-par치metros-de-text-completion-temperature-topp-y-n)
  - [1.6 Buenas pr치cticas al usar modelos de OpenAI](#16-buenas-pr치cticas-al-usar-modelos-de-openai)
  - [1.7 Chat Completions](#17-chat-completions)
  - [1.8 Actualizaciones de la API de OpenAI: GPT-4 disponible y modelos deprecados](#18-actualizaciones-de-la-api-de-openai-gpt-4-disponible-y-modelos-deprecados)
  - [Quiz de OpenAI API](#quiz-de-openai-api)
- [2 Fine-tuning de modelos de OpenAI](#2-fine-tuning-de-modelos-de-openai)
  - [2.1 쯇or qu칠 hacer fine-tuning a modelos de OpenAI?](#21-por-qu칠-hacer-fine-tuning-a-modelos-de-openai)
  - [2.2 Costos de uso de OpenAI: tokenizaci칩n de texto](#22-costos-de-uso-de-openai-tokenizaci칩n-de-texto)
  - [2.3 Configuraci칩n de entorno local de OpenAI con Anaconda](#23-configuraci칩n-de-entorno-local-de-openai-con-anaconda)
  - [2.4 Formato de datos para fine-tuning](#24-formato-de-datos-para-fine-tuning)
  - [2.5 Preparar datos para fine-tuning](#25-preparar-datos-para-fine-tuning)
  - [2.6 Fine-tuning de modelo de OpenAI](#26-fine-tuning-de-modelo-de-openai)
  - [2.7 쮺칩mo usar PlayGround de OpenAI para probar modelos?](#27-c칩mo-usar-playground-de-openai-para-probar-modelos)
  - [2.8 Pruebas al modelo con fine-tuning](#28-pruebas-al-modelo-con-fine-tuning)
  - [2.9 Optimizar el modelo: ajuste de par치metros en Playground](#29-optimizar-el-modelo-ajuste-de-par치metros-en-playground)
  - [2.10 Validaci칩n de modelos fine-tuned de OpenAI](#210-validaci칩n-de-modelos-fine-tuned-de-openai)
  - [Quiz de fine-tuning de modelos de OpenAI](#quiz-de-fine-tuning-de-modelos-de-openai)
- [3 Integraci칩n de modelo a aplicaci칩n de chat](#3-integraci칩n-de-modelo-a-aplicaci칩n-de-chat)
  - [3.1 쮺칩mo crear un chatbot con Telegram?](#31-c칩mo-crear-un-chatbot-con-telegram)
  - [3.2 Procesando la entrada del usuario para el chatbot](#32-procesando-la-entrada-del-usuario-para-el-chatbot)
  - [3.3 Prueba de env칤o de mensajes del chatbot](#33-prueba-de-env칤o-de-mensajes-del-chatbot)
  - [3.4 Funci칩n main() del chatbot](#34-funci칩n-main-del-chatbot)
  - [3.5 Integraci칩n del modelo de OpenAI a Telegram](#35-integraci칩n-del-modelo-de-openai-a-telegram)
  - [3.6 Manejo de errores y excepciones de la API de OpenAI](#36-manejo-de-errores-y-excepciones-de-la-api-de-openai)
  -[Quiz de integraci칩n de LLM a chat](#quiz-de-integraci칩n-de-llm-a-chat)
- [4 Conclusi칩n](#4-conclusi칩n)
  - [4.1 Recomendaciones finales y proyectos alternativos con el API de OpenAI](#41-recomendaciones-finales-y-proyectos-alternativos-con-el-api-de-openai)

# 1 OpenAI API

## 1.1 쮺칩mo usar la API de OpenAI en tu producto?

Entre las tareas m치s comunes que podemos hacer utilizando LLM's tenemos:

![1.png](ims%2F1%2F1.png)

- **Clasificaci칩n**: Los LLM's se pueden utilizar para clasificar textos en categor칤as espec칤ficas. Por ejemplo, pueden ser entrenados para clasificar correos electr칩nicos como "spam" o "no spam", noticias como "pol칤tica" o "deportes", comentarios como "positivos" o "negativos", entre otros.

- **Generaci칩n**: Los LLM's son muy 칰tiles para generar texto coherente y cohesivo a partir de un prompt o una pregunta inicial. Pueden ser utilizados para generar respuestas autom치ticas, redacciones, res칰menes de texto, descripciones de im치genes, entre otros.

- **Traducci칩n**: Los LLM's tambi칠n pueden ser utilizados para tareas de traducci칩n autom치tica. Al entrenarlos con datos de pares de idiomas, se puede lograr que el modelo genere traducciones coherentes y precisas de textos en diferentes idiomas.

- **Chatbots**: Los LLM's son una herramienta fundamental para la creaci칩n de chatbots. Pueden ser entrenados con datos de di치logos para que el modelo pueda responder preguntas, entablar conversaciones y simular interacciones humanas de manera natural.

- **Programaci칩n**: Los LLM's tambi칠n pueden utilizarse para generar c칩digo o ayudar en tareas de programaci칩n. Pueden ser entrenados con datos de c칩digo fuente y utilizados para autocompletar c칩digo, proporcionar sugerencias de c칩digo, corregir errores o incluso generar c칩digo completo a partir de una descripci칩n.

En este curso vamos a utilizar modelos tipo GPT para tareas relacionadas con Texto.

Veamos nuestro primer ejemplo de C칩digo. 쮺칩mo acceder a API de OpenAI desde c칩digo en Python?

> ## Nota: 
> El c칩digo de esta secci칩n lo puedes encontrar en: [1_tweet_sentiment.py](scripts%2F1_tweet_sentiment.py)

> Antes de continuar debemos instalar un par de librer칤as en python

En este ejercicio vamos a utilizar Chat GPT para hacer un clasificador de Sentimientos **positivos, neutrales, negativos** de **tweets**,

```bash
pip install python-dotenv
pip install openai
```

Antes de continuar asegurate de generar tu primer **API KEY** de OpenAI: https://platform.openai.com/account/api-keys

![2.png](ims%2F1%2F2.png)

Esta API KEY ES PERSONAL cu칤dala mucho y NO la compartas con nadie. Una vez generada tienes que guardarla porque no podr치s volver
a acceder a ella desde la p치gina de OpenAI.

Personalmente, voy a crear un archivo llamado `ap.env` en donde almacenar칠 mi `API KEY` de OpenAI

```commandline
OPENAI_API_KEY=sk-clavellenadeamor
```
De esta manera en Python cuando quiera acceder a ella no tendr칠 que tenerla visible al p칰blico. Vamos a empezar importando
las bibliotecas y accediendo a nuestra variable de entorno.
```python
import os
from dotenv import load_dotenv
import openai

# Carga las variables de entorno desde el archivo .env
load_dotenv("../envs/ap.env")
openai.api_key = os.getenv("OPENAI_API_KEY")
```

Ahora vamos a conocer un poco sobre nuestro primer m칠todo: `openai.Completion.create()`

- **model**: Especifica el modelo de lenguaje que se utilizar치 para generar el texto. Puedes elegir entre diferentes modelos, como "gpt-3.5-turbo" o "text-davinci-003". Cada modelo tiene diferentes caracter칤sticas y capacidades, por lo que es importante seleccionar el adecuado para tu caso de uso.

- **prompt**: Es el texto inicial o la consulta que proporcionas al modelo como punto de partida para generar el texto continuado. Puedes utilizar un prompt espec칤fico para guiar al modelo en la direcci칩n deseada o para establecer el contexto para la generaci칩n de texto.

- **temperature**: Controla la aleatoriedad de las respuestas generadas por el modelo. Un valor m치s bajo, como 0.2, produce respuestas m치s determin칤sticas y coherentes, mientras que un valor m치s alto, como 0.8, genera respuestas m치s creativas pero potencialmente menos coherentes.

- **max_tokens**: Define el n칰mero m치ximo de tokens que se generar치n en la respuesta. Un token puede ser una palabra o un car치cter, seg칰n el modelo que est칠s utilizando. Si deseas limitar la longitud del texto de salida, puedes establecer este par치metro en un valor adecuado.

- **top_p**: Tambi칠n conocido como "nucleus sampling" o "restricci칩n de token de parche". Limita la generaci칩n de texto a una distribuci칩n de probabilidad acumulativa superior a un cierto umbral. Un valor m치s bajo, como 0.2, har치 que las respuestas sean m치s restrictivas y enfocadas, mientras que un valor m치s alto, como 0.8, permitir치 una mayor diversidad en las respuestas generadas.

- **frequency_penalty**: Este par치metro controla la preferencia del modelo por evitar la repetici칩n de frases. Un valor m치s alto, como 0.6, penalizar치 m치s la repetici칩n y har치 que el modelo evite generar frases similares. Un valor de 0 no penaliza la repetici칩n.

- **presence_penalty**: Este par치metro controla la preferencia del modelo por evitar la menci칩n de ciertas palabras o temas en el texto de salida. Un valor m치s alto, como 0.6, penalizar치 m치s la presencia de ciertas palabras o temas y har치 que el modelo evite mencionarlos. Un valor de 0 no penaliza la presencia de palabras o temas espec칤ficos.


Ahora vamos a presentar nuestra primera petici칩n al API de OpenAI:

```python
response = openai.Completion.create(
  model="text-davinci-003",
  prompt="Decide si el sentimiento de un Tweet es positivo, neutral, o negativo. \
  \n\nTweet: \"#LoNuevoEnPlatzi es el Platzibot 游뱄. Un asistente creado con Inteligencia Artificial para acompa침arte en tu proceso de aprendizaje.\
  \"\nSentiment:",
  temperature=0,
  max_tokens=60,
  top_p=1.0,
  frequency_penalty=0.5,
  presence_penalty=0.0
)
print(response.choices[0].text)
```
Respuesta esperada:
```commandline
 Positivo
```

Excelente, en esta clase hemos aprendido a conectarnos al API de OpenAI a trav칠s de su biblioteca en Python, hemos creado
un archivo .env para almacenar nuestra API KEY y hemos conocido algunos de los par치metros b치sicos que tiene el m칠todo
`Completion.create` y hemos logrado hacer un clasificador de sentimientos de tweets.



## 1.2 Conociendo la documentaci칩n de la API de OpenAI

## 1.3 Cargar modelo de la API de OpenAI con Python

## 1.4 Creaci칩n de ejemplo utilizando la API de OpenAI

## 1.5 Par치metros de Text Completion: temperature, top_p y n

## 1.6 Buenas pr치cticas al usar modelos de OpenAI

## 1.7 Chat Completions

## 1.8 Actualizaciones de la API de OpenAI: GPT-4 disponible y modelos deprecados

## Quiz de OpenAI API

# 2 Fine-tuning de modelos de OpenAI

## 2.1 쯇or qu칠 hacer fine-tuning a modelos de OpenAI?

## 2.2 Costos de uso de OpenAI: tokenizaci칩n de texto

## 2.3 Configuraci칩n de entorno local de OpenAI con Anaconda

## 2.4 Formato de datos para fine-tuning

## 2.5 Preparar datos para fine-tuning

## 2.6 Fine-tuning de modelo de OpenAI

## 2.7 쮺칩mo usar PlayGround de OpenAI para probar modelos?

## 2.8 Pruebas al modelo con fine-tuning

## 2.9 Optimizar el modelo: ajuste de par치metros en Playground

## 2.10 Validaci칩n de modelos fine-tuned de OpenAI

## Quiz de fine-tuning de modelos de OpenAI

# 3 Integraci칩n de modelo a aplicaci칩n de chat

## 3.1 쮺칩mo crear un chatbot con Telegram?

## 3.2 Procesando la entrada del usuario para el chatbot

## 3.3 Prueba de env칤o de mensajes del chatbot

## 3.4 Funci칩n main() del chatbot

## 3.5 Integraci칩n del modelo de OpenAI a Telegram

## 3.6 Manejo de errores y excepciones de la API de OpenAI

## Quiz de integraci칩n de LLM a chat

# 4 Conclusi칩n

## 4.1 Recomendaciones finales y proyectos alternativos con el API de OpenAI